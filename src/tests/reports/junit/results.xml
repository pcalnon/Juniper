<?xml version="1.0" encoding="utf-8"?><testsuites name="pytest tests"><testsuite name="pytest" errors="2" failures="11" skipped="0" tests="25" time="10308.432" timestamp="2026-01-19T15:27:08.285069-06:00" hostname="yamaguchi"><testcase classname="" name="integration.test_serialization" time="0.000"><error message="collection failure">ImportError while importing test module '/home/pcalnon/Development/python/Juniper/JuniperCascor/juniper_cascor/src/tests/integration/test_serialization.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/opt/miniforge3/envs/JuniperCascor/lib/python3.14/importlib/__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src/tests/integration/test_serialization.py:34: in &lt;module&gt;
    from cascade_correlation_config.cascade_correlation_config import (  # trunk-ignore(ruff/E402)
E   ModuleNotFoundError: No module named 'cascade_correlation_config'</error></testcase><testcase classname="" name="unit.test_hdf5" time="0.000"><error message="collection failure">ImportError while importing test module '/home/pcalnon/Development/python/Juniper/JuniperCascor/juniper_cascor/src/tests/unit/test_hdf5.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/opt/miniforge3/envs/JuniperCascor/lib/python3.14/importlib/__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src/tests/unit/test_hdf5.py:10: in &lt;module&gt;
    from cascade_correlation_config.cascade_correlation_config import CascadeCorrelationConfig
E   ModuleNotFoundError: No module named 'cascade_correlation_config'</error></testcase><testcase classname="integration.test_comprehensive_serialization.TestDeterministicTrainingResume" name="test_deterministic_training_resume" time="149.544"><failure message="AssertionError: &#10;Arrays are not almost equal to 5 decimals&#10;Resumed training diverged from continuous training&#10;Mismatched elements: 10 / 10 (100%)&#10;First 5 mismatches are at indices:&#10; [0, 0]: -0.06055125594139099 (ACTUAL), -0.09020629525184631 (DESIRED)&#10; [1, 0]: 0.17347075045108795 (ACTUAL), 0.14152517914772034 (DESIRED)&#10; [2, 0]: 0.6829667091369629 (ACTUAL), 0.6615568399429321 (DESIRED)&#10; [3, 0]: -0.4994625747203827 (ACTUAL), -0.5184578895568848 (DESIRED)&#10; [4, 0]: 0.5226701498031616 (ACTUAL), 0.5043010711669922 (DESIRED)&#10;Max absolute difference among violations: 0.03194557&#10;Max relative difference among violations: 0.5111792&#10; ACTUAL: array([[-0.06055],&#10;       [ 0.17347],&#10;       [ 0.68297],...&#10; DESIRED: array([[-0.09021],&#10;       [ 0.14153],&#10;       [ 0.66156],...">self = &lt;test_comprehensive_serialization.TestDeterministicTrainingResume testMethod=test_deterministic_training_resume&gt;

    def test_deterministic_training_resume(self):
        """
        Critical test: Train → Save → Load → Resume should be identical to continuous training.
        This is the most important test for deterministic reproducibility.
        """
        # Setup
        config = CascadeCorrelationConfig(
            input_size=2,
            output_size=1,
            candidate_pool_size=3,
            candidate_epochs=10,
            output_epochs=20,
            max_hidden_units=2,
            random_seed=42,
        )
    
        # Create test data
        torch.manual_seed(42)
        x_train = torch.randn(50, 2)
        y_train = (x_train[:, 0] &gt; x_train[:, 1]).float().unsqueeze(1)
    
        # Scenario A: Train for 20 epochs, save, train for 20 more
        network_a = CascadeCorrelationNetwork(config=config)
        network_a.fit(
            x_train=x_train,
            y_train=y_train,
            max_epochs=20
        )
        serializer = CascadeHDF5Serializer()
        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as f:
            temp_file = f.name
        try:
            success = serializer.save_network(network_a, temp_file)
            self.assertTrue(success, "Failed to save network")
            network_a_resumed = serializer.load_network(temp_file)
            self.assertIsNotNone(network_a_resumed, "Failed to load network")
            network_a_resumed.fit(x_train, y_train, epochs=20)
    
            # Scenario B: Train continuously for 40 epochs
            network_b = CascadeCorrelationNetwork(config=config)
            network_b.fit(x_train, y_train, epochs=40)
    
            # Verify outputs are identical
            torch.manual_seed(999)  # Different seed for test data
            test_x = torch.randn(10, 2)
            output_a = network_a_resumed.forward(test_x)
            output_b = network_b.forward(test_x)
&gt;           np.testing.assert_array_almost_equal(
                output_a.detach().numpy(),
                output_b.detach().numpy(),
                decimal=5,
                err_msg="Resumed training diverged from continuous training",
            )
E           AssertionError: 
E           Arrays are not almost equal to 5 decimals
E           Resumed training diverged from continuous training
E           Mismatched elements: 10 / 10 (100%)
E           First 5 mismatches are at indices:
E            [0, 0]: -0.06055125594139099 (ACTUAL), -0.09020629525184631 (DESIRED)
E            [1, 0]: 0.17347075045108795 (ACTUAL), 0.14152517914772034 (DESIRED)
E            [2, 0]: 0.6829667091369629 (ACTUAL), 0.6615568399429321 (DESIRED)
E            [3, 0]: -0.4994625747203827 (ACTUAL), -0.5184578895568848 (DESIRED)
E            [4, 0]: 0.5226701498031616 (ACTUAL), 0.5043010711669922 (DESIRED)
E           Max absolute difference among violations: 0.03194557
E           Max relative difference among violations: 0.5111792
E            ACTUAL: array([[-0.06055],
E                  [ 0.17347],
E                  [ 0.68297],...
E            DESIRED: array([[-0.09021],
E                  [ 0.14153],
E                  [ 0.66156],...

src/tests/integration/test_comprehensive_serialization.py:79: AssertionError</failure></testcase><testcase classname="integration.test_comprehensive_serialization.TestHiddenUnitsPreservation" name="test_hidden_units_preservation" time="1.698" /><testcase classname="integration.test_comprehensive_serialization.TestConfigRoundtrip" name="test_config_roundtrip" time="1.685" /><testcase classname="integration.test_comprehensive_serialization.TestActivationFunctionRestoration" name="test_activation_function_restoration" time="4.834" /><testcase classname="integration.test_comprehensive_serialization.TestTorchRandomStateRestoration" name="test_torch_random_state_restoration" time="2.452" /><testcase classname="integration.test_comprehensive_serialization.TestHistoryPreservation" name="test_history_preservation" time="1.644" /><testcase classname="integration.test_spiral_problem.TestSpiralProblemBasic" name="test_2_spiral_learning" time="612.889"><failure message="AssertionError: Network did not learn: initial_loss=0.243668, final_loss=0.243668: improvement=0.000000 &lt; min_improvement=0.01">self = &lt;test_spiral_problem.TestSpiralProblemBasic object at 0x77066287fb10&gt;, spiral_network = &lt;cascade_correlation.cascade_correlation.CascadeCorrelationNetwork object at 0x770662843a10&gt;

    @pytest.mark.integration
    @pytest.mark.spiral
    @pytest.mark.slow
    def test_2_spiral_learning(self, spiral_network):
        """Test that network can learn 2-spiral problem."""
        set_deterministic_behavior(42)
    
        # Generate 2-spiral data
        # x, y, info = SpiralDataGenerator.generate_2_spiral(
        x, y, _ = SpiralDataGenerator.generate_2_spiral(
            n_per_spiral=50,
            noise=0.05,
            seed=42
        )
    
        # Train network
        initial_accuracy = spiral_network.calculate_accuracy(x, y)
        history, elapsed_time = measure_training_time(
            spiral_network, x, y, max_epochs=10, early_stopping=False
        )
        final_accuracy = spiral_network.calculate_accuracy(x, y)
        # Verify learning occurred
&gt;       assert_network_learns(
            initial_loss=history['train_loss'][0],
            final_loss=history['train_loss'][-1],
            min_improvement=0.01
        )

src/tests/integration/test_spiral_problem.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

initial_loss = 0.2436680942773819, final_loss = 0.2436680942773819, min_improvement = 0.01, msg = 'Network did not learn: initial_loss=0.243668, final_loss=0.243668'

    def assert_network_learns(
        initial_loss: float,
        final_loss: float,
        min_improvement: float = 0.01,
        msg: Optional[str] = None
    ) -&gt; None:
        """
        Assert that network shows learning (loss improvement).
    
        Args:
            initial_loss: Loss at start of training
            final_loss: Loss at end of training
            min_improvement: Minimum relative improvement required
            msg: Optional error message
        """
        if msg is None:
            msg = f"Network did not learn: initial_loss={initial_loss:.6f}, final_loss={final_loss:.6f}"
    
        improvement = (initial_loss - final_loss) / initial_loss
&gt;       assert improvement &gt;= min_improvement, f"{msg}: improvement={improvement:.6f} &lt; min_improvement={min_improvement}" # trunk-ignore(bandit/B101)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AssertionError: Network did not learn: initial_loss=0.243668, final_loss=0.243668: improvement=0.000000 &lt; min_improvement=0.01

src/tests/helpers/assertions.py:340: AssertionError</failure></testcase><testcase classname="integration.test_spiral_problem.TestSpiralProblemBasic" name="test_3_spiral_learning" time="763.440"><failure message="assert 0.35 &gt; 0.35">self = &lt;test_spiral_problem.TestSpiralProblemBasic object at 0x77066287fed0&gt;, spiral_network = &lt;cascade_correlation.cascade_correlation.CascadeCorrelationNetwork object at 0x770656be7380&gt;

    @pytest.mark.integration
    @pytest.mark.spiral
    def test_3_spiral_learning(self, spiral_network):
        """Test that network can learn 3-spiral problem."""
        set_deterministic_behavior(42)
    
        # Generate 3-spiral data
        # x, y, info = SpiralDataGenerator.generate_n_spiral(
        x, y, _ = SpiralDataGenerator.generate_n_spiral(
            n_spirals=3,
            n_per_spiral=40,
            noise=0.03,
            seed=42
        )
    
        # Adjust network for 3-class problem
        spiral_network.output_size = 3
        spiral_network.output_weights = torch.randn(
            spiral_network.input_size, 3, requires_grad=True
        ) * spiral_network.random_value_scale
        spiral_network.output_bias = torch.randn(3, requires_grad=True) * spiral_network.random_value_scale
    
        # Train network
        initial_accuracy = spiral_network.calculate_accuracy(x, y)
        history = spiral_network.fit(x, y, max_epochs=8)
        final_accuracy = spiral_network.calculate_accuracy(x, y)
    
        # Verify learning
&gt;       assert final_accuracy &gt; initial_accuracy  # trunk-ignore(bandit/B101)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       assert 0.35 &gt; 0.35

src/tests/integration/test_spiral_problem.py:100: AssertionError</failure></testcase><testcase classname="integration.test_spiral_problem.TestSpiralProblemProgressive" name="test_n_spiral_difficulty_progression[2]" time="450.225"><failure message="assert 0.5 &gt;= 0.5166666666666667">self = &lt;test_spiral_problem.TestSpiralProblemProgressive object at 0x7706628842d0&gt;, n_spirals = 2

    @pytest.mark.integration
    @pytest.mark.spiral
    @pytest.mark.slow
    @pytest.mark.parametrize("n_spirals", [2, 3, 4])
    def test_n_spiral_difficulty_progression(self, n_spirals):
        """Test that network can handle increasing spiral complexity."""
        set_deterministic_behavior(42)
    
        # Create network configured for n-spiral problem
        from cascade_correlation.cascade_correlation import CascadeCorrelationNetwork
        network = CascadeCorrelationNetwork.create_simple_network(
            input_size=2,
            output_size=n_spirals,
            learning_rate=0.05,
            max_hidden_units=min(8, n_spirals * 2),
            candidate_pool_size=12,
            correlation_threshold=0.15
        )
    
        # Generate n-spiral data
        # x, y, info = SpiralDataGenerator.generate_n_spiral(
        x, y, _ = SpiralDataGenerator.generate_n_spiral(
            n_spirals=n_spirals,
            n_per_spiral=30,
            noise=0.02,
            seed=42
        )
    
        # Train network
        initial_accuracy = network.calculate_accuracy(x, y)
        history = network.fit(x, y, max_epochs=6)
        final_accuracy = network.calculate_accuracy(x, y)
    
        # Basic learning verification
&gt;       assert final_accuracy &gt;= initial_accuracy # trunk-ignore(bandit/B101)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       assert 0.5 &gt;= 0.5166666666666667

src/tests/integration/test_spiral_problem.py:147: AssertionError</failure></testcase><testcase classname="integration.test_spiral_problem.TestSpiralProblemProgressive" name="test_n_spiral_difficulty_progression[3]" time="580.515"><failure message="assert 0.37777777777777777 &gt; (0.3333333333333333 * 1.2)">self = &lt;test_spiral_problem.TestSpiralProblemProgressive object at 0x770662884410&gt;, n_spirals = 3

    @pytest.mark.integration
    @pytest.mark.spiral
    @pytest.mark.slow
    @pytest.mark.parametrize("n_spirals", [2, 3, 4])
    def test_n_spiral_difficulty_progression(self, n_spirals):
        """Test that network can handle increasing spiral complexity."""
        set_deterministic_behavior(42)
    
        # Create network configured for n-spiral problem
        from cascade_correlation.cascade_correlation import CascadeCorrelationNetwork
        network = CascadeCorrelationNetwork.create_simple_network(
            input_size=2,
            output_size=n_spirals,
            learning_rate=0.05,
            max_hidden_units=min(8, n_spirals * 2),
            candidate_pool_size=12,
            correlation_threshold=0.15
        )
    
        # Generate n-spiral data
        # x, y, info = SpiralDataGenerator.generate_n_spiral(
        x, y, _ = SpiralDataGenerator.generate_n_spiral(
            n_spirals=n_spirals,
            n_per_spiral=30,
            noise=0.02,
            seed=42
        )
    
        # Train network
        initial_accuracy = network.calculate_accuracy(x, y)
        history = network.fit(x, y, max_epochs=6)
        final_accuracy = network.calculate_accuracy(x, y)
    
        # Basic learning verification
        assert final_accuracy &gt;= initial_accuracy # trunk-ignore(bandit/B101)
    
        # Expected accuracy should decrease with complexity but still be above random
        random_accuracy = 1.0 / n_spirals
        # At least 20% better than random
&gt;       assert final_accuracy &gt; random_accuracy * 1.2  # trunk-ignore(bandit/B101)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       assert 0.37777777777777777 &gt; (0.3333333333333333 * 1.2)

src/tests/integration/test_spiral_problem.py:152: AssertionError</failure></testcase><testcase classname="integration.test_spiral_problem.TestSpiralProblemProgressive" name="test_n_spiral_difficulty_progression[4]" time="708.897"><failure message="assert 0.26666666666666666 &gt; (0.25 * 1.2)">self = &lt;test_spiral_problem.TestSpiralProblemProgressive object at 0x7706627f1350&gt;, n_spirals = 4

    @pytest.mark.integration
    @pytest.mark.spiral
    @pytest.mark.slow
    @pytest.mark.parametrize("n_spirals", [2, 3, 4])
    def test_n_spiral_difficulty_progression(self, n_spirals):
        """Test that network can handle increasing spiral complexity."""
        set_deterministic_behavior(42)
    
        # Create network configured for n-spiral problem
        from cascade_correlation.cascade_correlation import CascadeCorrelationNetwork
        network = CascadeCorrelationNetwork.create_simple_network(
            input_size=2,
            output_size=n_spirals,
            learning_rate=0.05,
            max_hidden_units=min(8, n_spirals * 2),
            candidate_pool_size=12,
            correlation_threshold=0.15
        )
    
        # Generate n-spiral data
        # x, y, info = SpiralDataGenerator.generate_n_spiral(
        x, y, _ = SpiralDataGenerator.generate_n_spiral(
            n_spirals=n_spirals,
            n_per_spiral=30,
            noise=0.02,
            seed=42
        )
    
        # Train network
        initial_accuracy = network.calculate_accuracy(x, y)
        history = network.fit(x, y, max_epochs=6)
        final_accuracy = network.calculate_accuracy(x, y)
    
        # Basic learning verification
        assert final_accuracy &gt;= initial_accuracy # trunk-ignore(bandit/B101)
    
        # Expected accuracy should decrease with complexity but still be above random
        random_accuracy = 1.0 / n_spirals
        # At least 20% better than random
&gt;       assert final_accuracy &gt; random_accuracy * 1.2  # trunk-ignore(bandit/B101)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       assert 0.26666666666666666 &gt; (0.25 * 1.2)

src/tests/integration/test_spiral_problem.py:152: AssertionError</failure></testcase><testcase classname="integration.test_spiral_problem.TestSpiralProblemRobustness" name="test_spiral_noise_robustness[0.01]" time="596.895"><failure message="assert 0.525 &gt; 0.55">self = &lt;test_spiral_problem.TestSpiralProblemRobustness object at 0x77066287fd90&gt;, spiral_network = &lt;cascade_correlation.cascade_correlation.CascadeCorrelationNetwork object at 0x770656be7cb0&gt;, noise_level = 0.01

    @pytest.mark.integration
    @pytest.mark.spiral
    @pytest.mark.parametrize("noise_level", [0.01, 0.05, 0.1])
    def test_spiral_noise_robustness(self, spiral_network, noise_level):
        """Test network performance with different noise levels."""
        set_deterministic_behavior(42)
    
        # Generate noisy spiral data
        # x, y, info = SpiralDataGenerator.generate_2_spiral(
        x, y, _ = SpiralDataGenerator.generate_2_spiral(
            n_per_spiral=40,
            noise=noise_level,
            seed=42
        )
    
        # Train network
        initial_accuracy = spiral_network.calculate_accuracy(x, y)
        history = spiral_network.fit(x, y, max_epochs=6)
        final_accuracy = spiral_network.calculate_accuracy(x, y)
    
        # Should learn even with noise, though performance may degrade
        assert final_accuracy &gt;= initial_accuracy # trunk-ignore(bandit/B101)
    
        # Performance should still be better than random (0.5 for 2-class)
        if noise_level &lt;= 0.05:  # sourcery skip: no-conditionals-in-tests
            # Should handle small noise well
&gt;           assert final_accuracy &gt; 0.55  # trunk-ignore(bandit/B101)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           assert 0.525 &gt; 0.55

src/tests/integration/test_spiral_problem.py:188: AssertionError</failure></testcase><testcase classname="integration.test_spiral_problem.TestSpiralProblemRobustness" name="test_spiral_noise_robustness[0.05]" time="598.973"><failure message="assert 0.55 &gt; 0.55">self = &lt;test_spiral_problem.TestSpiralProblemRobustness object at 0x770662884550&gt;, spiral_network = &lt;cascade_correlation.cascade_correlation.CascadeCorrelationNetwork object at 0x7706560f01a0&gt;, noise_level = 0.05

    @pytest.mark.integration
    @pytest.mark.spiral
    @pytest.mark.parametrize("noise_level", [0.01, 0.05, 0.1])
    def test_spiral_noise_robustness(self, spiral_network, noise_level):
        """Test network performance with different noise levels."""
        set_deterministic_behavior(42)
    
        # Generate noisy spiral data
        # x, y, info = SpiralDataGenerator.generate_2_spiral(
        x, y, _ = SpiralDataGenerator.generate_2_spiral(
            n_per_spiral=40,
            noise=noise_level,
            seed=42
        )
    
        # Train network
        initial_accuracy = spiral_network.calculate_accuracy(x, y)
        history = spiral_network.fit(x, y, max_epochs=6)
        final_accuracy = spiral_network.calculate_accuracy(x, y)
    
        # Should learn even with noise, though performance may degrade
        assert final_accuracy &gt;= initial_accuracy # trunk-ignore(bandit/B101)
    
        # Performance should still be better than random (0.5 for 2-class)
        if noise_level &lt;= 0.05:  # sourcery skip: no-conditionals-in-tests
            # Should handle small noise well
&gt;           assert final_accuracy &gt; 0.55  # trunk-ignore(bandit/B101)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           assert 0.55 &gt; 0.55

src/tests/integration/test_spiral_problem.py:188: AssertionError</failure></testcase><testcase classname="integration.test_spiral_problem.TestSpiralProblemRobustness" name="test_spiral_noise_robustness[0.1]" time="606.776" /><testcase classname="integration.test_spiral_problem.TestSpiralProblemRobustness" name="test_spiral_data_size_scaling[20]" time="608.843"><failure message="assert 0.5 &gt; 0.525">self = &lt;test_spiral_problem.TestSpiralProblemRobustness object at 0x7706627f16e0&gt;, spiral_network = &lt;cascade_correlation.cascade_correlation.CascadeCorrelationNetwork object at 0x7706560f0590&gt;, n_per_spiral = 20

    @pytest.mark.integration
    @pytest.mark.spiral
    @pytest.mark.parametrize("n_per_spiral", [20, 50, 100])
    def test_spiral_data_size_scaling(self, spiral_network, n_per_spiral):
        """Test network performance with different dataset sizes."""
        set_deterministic_behavior(42)
    
        # Generate spiral data of different sizes
        # x, y, info = SpiralDataGenerator.generate_2_spiral(
        x, y, _ = SpiralDataGenerator.generate_2_spiral(
            n_per_spiral=n_per_spiral,
            noise=0.03,
            seed=42
        )
    
        # Train network
        initial_accuracy = spiral_network.calculate_accuracy(x, y)
        history = spiral_network.fit(x, y, max_epochs=5)
        final_accuracy = spiral_network.calculate_accuracy(x, y)
    
        # Should learn regardless of data size
&gt;       assert final_accuracy &gt; initial_accuracy # trunk-ignore(bandit/B101)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       assert 0.5 &gt; 0.525

src/tests/integration/test_spiral_problem.py:216: AssertionError</failure></testcase><testcase classname="integration.test_spiral_problem.TestSpiralProblemRobustness" name="test_spiral_data_size_scaling[50]" time="625.065" /><testcase classname="integration.test_spiral_problem.TestSpiralProblemRobustness" name="test_spiral_data_size_scaling[100]" time="631.105" /><testcase classname="integration.test_spiral_problem.TestSpiralProblemVisualization" name="test_spiral_training_progression" time="617.018"><failure message="assert 0.5 &gt; 0.5">self = &lt;test_spiral_problem.TestSpiralProblemVisualization object at 0x770662884910&gt;, spiral_network = &lt;cascade_correlation.cascade_correlation.CascadeCorrelationNetwork object at 0x7706560f06e0&gt;

    @pytest.mark.integration
    @pytest.mark.spiral
    def test_spiral_training_progression(self, spiral_network):
        """Test and analyze training progression on spiral problem."""
        set_deterministic_behavior(42)
    
        # Generate spiral data
        # x, y, info = SpiralDataGenerator.generate_2_spiral(
        x, y, _ = SpiralDataGenerator.generate_2_spiral(
            n_per_spiral=60,
            noise=0.04,
            seed=42
        )
    
        # Split into train/validation
        n_train = int(0.8 * len(x))
        indices = torch.randperm(len(x))
        train_indices, val_indices = indices[:n_train], indices[n_train:]
    
        x_train, y_train = x[train_indices], y[train_indices]
        x_val, y_val = x[val_indices], y[val_indices]
    
        # Train with validation
        history = spiral_network.fit(
            x_train, y_train,
            x_val, y_val,
            max_epochs=8,
            early_stopping=True
        )
    
        # Analyze training progression
        assert len(history['train_loss']) &gt; 0 # trunk-ignore(bandit/B101)
        assert len(history['train_accuracy']) &gt; 0 # trunk-ignore(bandit/B101)
    
        if 'value_loss' in history and history['value_loss']:  # sourcery skip: no-conditionals-in-tests
            assert len(history['value_loss']) &gt; 0 # trunk-ignore(bandit/B101)
            assert len(history['value_accuracy']) &gt; 0 # trunk-ignore(bandit/B101)
    
            # Validation accuracy should be reasonable
            final_val_accuracy = history['value_accuracy'][-1]
&gt;           assert final_val_accuracy &gt; 0.5 # trunk-ignore(bandit/B101)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           assert 0.5 &gt; 0.5

src/tests/integration/test_spiral_problem.py:268: AssertionError</failure></testcase><testcase classname="integration.test_spiral_problem.TestSpiralProblemEdgeCases" name="test_minimal_spiral_data" time="336.431" /><testcase classname="integration.test_spiral_problem.TestSpiralProblemEdgeCases" name="test_perfect_spiral_separation" time="595.083"><failure message="assert 0.5166666666666667 &gt; 0.5166666666666667">self = &lt;test_spiral_problem.TestSpiralProblemEdgeCases object at 0x770662884cd0&gt;, spiral_network = &lt;cascade_correlation.cascade_correlation.CascadeCorrelationNetwork object at 0x7706560f0440&gt;

    @pytest.mark.integration
    @pytest.mark.spiral
    def test_perfect_spiral_separation(self, spiral_network):
        """Test network with perfectly separated spiral data."""
        set_deterministic_behavior(42)
    
        # Generate data with no noise (perfect separation)
        # x, y, info = SpiralDataGenerator.generate_2_spiral(
        x, y, _ = SpiralDataGenerator.generate_2_spiral(
            n_per_spiral=30,
            noise=0.0,  # No noise - perfect separation
            seed=42
        )
    
        # Train network
        initial_accuracy = spiral_network.calculate_accuracy(x, y)
        history = spiral_network.fit(x, y, max_epochs=8)
        final_accuracy = spiral_network.calculate_accuracy(x, y)
    
        # Should achieve very high accuracy with perfect data
&gt;       assert final_accuracy &gt; initial_accuracy  # trunk-ignore(bandit/B101)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       assert 0.5166666666666667 &gt; 0.5166666666666667

src/tests/integration/test_spiral_problem.py:332: AssertionError</failure></testcase><testcase time="0.001" /></testsuite></testsuites>